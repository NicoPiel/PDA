{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs für die Berechnung: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nico/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Ein Zufalls-Seed für Reproduzierbarkeit\n",
    "np.random.seed(42)\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.impute import KNNImputer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks, utils\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "print(f\"GPUs für die Berechnung: {len(tf.config.experimental.list_physical_devices('GPU'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# OTU Metadaten einlesen\n",
    "df = pd.read_csv(\"NIHMS841832-supplement-1.csv\", sep=',')\n",
    "\n",
    "# Ergebnisse des Feature Tables einlesen\n",
    "feature = pd.read_csv('feature_table_otu.txt', sep='\\t').T\n",
    "feature = feature[1:][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Gesunde Kontrollgruppe\n",
    "HC = df[df.ibd_subtype.eq(\"HC\")]\n",
    "\n",
    "y = []\n",
    "for row in feature.index:\n",
    "    if any(True for val in HC['sample_name'] if val == row):\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "\n",
    "X = feature.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3101</th>\n",
       "      <th>3102</th>\n",
       "      <th>3103</th>\n",
       "      <th>3104</th>\n",
       "      <th>3105</th>\n",
       "      <th>3106</th>\n",
       "      <th>3107</th>\n",
       "      <th>3108</th>\n",
       "      <th>3109</th>\n",
       "      <th>3110</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD335</th>\n",
       "      <td>34292.0</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>18413.0</td>\n",
       "      <td>9981.0</td>\n",
       "      <td>7071.0</td>\n",
       "      <td>6881.0</td>\n",
       "      <td>5411.0</td>\n",
       "      <td>5335.0</td>\n",
       "      <td>5289.0</td>\n",
       "      <td>4741.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD643</th>\n",
       "      <td>15243.0</td>\n",
       "      <td>64328.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4507.0</td>\n",
       "      <td>3216.0</td>\n",
       "      <td>15630.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD539</th>\n",
       "      <td>22182.0</td>\n",
       "      <td>21589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11501.0</td>\n",
       "      <td>33619.0</td>\n",
       "      <td>3638.0</td>\n",
       "      <td>5053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD078</th>\n",
       "      <td>0.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>2305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19734.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0        1        2       3       4        5     \\\n",
       "1629.SubjectIBD335  34292.0  20670.0  18413.0  9981.0  7071.0   6881.0   \n",
       "1629.SubjectIBD643  15243.0  64328.0      0.0     0.0     0.0      4.0   \n",
       "1629.SubjectIBD539  22182.0  21589.0      0.0  1365.0     0.0  11501.0   \n",
       "1629.SubjectIBD078      0.0    805.0      0.0     0.0     0.0      4.0   \n",
       "1629.SubjectIBD671      0.0  19734.0      0.0     0.0     0.0      0.0   \n",
       "\n",
       "                       6       7        8       9     ... 3101 3102 3103 3104  \\\n",
       "1629.SubjectIBD335   5411.0  5335.0   5289.0  4741.0  ...  0.0  0.0  0.0  0.0   \n",
       "1629.SubjectIBD643   4507.0  3216.0  15630.0   199.0  ...  0.0  0.0  0.0  0.0   \n",
       "1629.SubjectIBD539  33619.0  3638.0   5053.0     0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1629.SubjectIBD078    330.0  2305.0      0.0     8.0  ...  0.0  0.0  0.0  0.0   \n",
       "1629.SubjectIBD671    215.0     0.0      0.0   699.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                   3105 3106 3107 3108 3109 3110  \n",
       "1629.SubjectIBD335  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1629.SubjectIBD643  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1629.SubjectIBD539  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1629.SubjectIBD078  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1629.SubjectIBD671  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 3111 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def nn(random_state):\n",
    "    # Split\n",
    "    # TODO: Andere Aufteilung\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = random_state)\n",
    "\n",
    "    # Das Modell soll aufhören zu rechnen, falls es keine nennenswerten Verbesserungen mehr gibt\n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        min_delta=0.001,\n",
    "        patience=64,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Das NN besteht aus einer Mischung von Dense-, Normalization- und Dropout-Layern.\n",
    "    # Dropout führt allem Anschein nach zu schlechterem F1\n",
    "    # Weniger LUs führen zu besseren Ergebnissen\n",
    "    network = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "        #layers.Dropout(rate=0.5),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        #layers.Dropout(rate=0.5),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    # NN kompilieren\n",
    "    network.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[keras.metrics.Accuracy()]\n",
    "    )\n",
    "\n",
    "    # NN trainieren\n",
    "    history = network.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        batch_size=64,\n",
    "        epochs=512,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Scores berechnen\n",
    "    # history_df = pd.DataFrame(history.history)\n",
    "\n",
    "    y_pred = np.floor(network.predict(X_test))\n",
    "    report = sklearn.metrics.classification_report(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    # confusion_matrix = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "    # print(confusion_matrix)\n",
    "    # print(report)\n",
    "    return f1, report, network\n",
    "\n",
    "    # history_df.loc[5:, ['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[244   4]\n",
      " [  8  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       248\n",
      "           1       0.81      0.68      0.74        25\n",
      "\n",
      "    accuracy                           0.96       273\n",
      "   macro avg       0.89      0.83      0.86       273\n",
      "weighted avg       0.95      0.96      0.95       273\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8575652173913044,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.97      0.98      0.98       248\\n           1       0.81      0.68      0.74        25\\n\\n    accuracy                           0.96       273\\n   macro avg       0.89      0.83      0.86       273\\nweighted avg       0.95      0.96      0.95       273\\n',\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7fa00c9396d0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 100 verschiedene Modelle trainieren und in einen DataFrame speichern\n",
    "# Das kann ein paar Stunden dauern\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i in np.arange(100):\n",
    "    f1, report, model = nn(i)\n",
    "    results[i] = [model, f1, report]\n",
    "    clear_output()\n",
    "    df_results = pd.DataFrame.from_dict(results, orient='index', columns=['model', 'f1', 'report'])\n",
    "    display(df_results)\n",
    "\n",
    "\n",
    "#df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame nach bestem F1-Score sortieren\n",
    "df_results_sorted = df_results.sort_values(by=['f1'], ascending=False)\n",
    "\n",
    "# Die besten 10 Modelle speichern\n",
    "for i in np.arange(10):\n",
    "    df_results_sorted.iloc[i].model.save(f'models/best_otu/model{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[253   0]\n",
      " [  4  16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       253\n",
      "           1       1.00      0.80      0.89        20\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.99      0.90      0.94       273\n",
      "weighted avg       0.99      0.99      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[247   1]\n",
      " [  4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       248\n",
      "           1       0.95      0.84      0.89        25\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.97      0.92      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[247   1]\n",
      " [  4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       248\n",
      "           1       0.95      0.84      0.89        25\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.97      0.92      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[251   0]\n",
      " [  2  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       251\n",
      "           1       1.00      0.91      0.95        22\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       1.00      0.95      0.97       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[247   0]\n",
      " [  5  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       247\n",
      "           1       1.00      0.81      0.89        26\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.99      0.90      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[248   1]\n",
      " [  3  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       249\n",
      "           1       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.97      0.94      0.95       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[244   0]\n",
      " [  3  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       244\n",
      "           1       1.00      0.90      0.95        29\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.99      0.95      0.97       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[249   0]\n",
      " [  4  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       249\n",
      "           1       1.00      0.83      0.91        24\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.99      0.92      0.95       273\n",
      "weighted avg       0.99      0.99      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[245   1]\n",
      " [  4  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       246\n",
      "           1       0.96      0.85      0.90        27\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.97      0.92      0.95       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[242   1]\n",
      " [  7  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       243\n",
      "           1       0.96      0.77      0.85        30\n",
      "\n",
      "    accuracy                           0.97       273\n",
      "   macro avg       0.97      0.88      0.92       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[240   1]\n",
      " [  4  28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       241\n",
      "           1       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.97      0.94      0.95       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[246   1]\n",
      " [  3  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       247\n",
      "           1       0.96      0.88      0.92        26\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.97      0.94      0.96       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[245   1]\n",
      " [  2  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       246\n",
      "           1       0.96      0.93      0.94        27\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.98      0.96      0.97       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[254   0]\n",
      " [  5  14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       254\n",
      "           1       1.00      0.74      0.85        19\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.99      0.87      0.92       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[247   1]\n",
      " [  4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       248\n",
      "           1       0.95      0.84      0.89        25\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.97      0.92      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[252   0]\n",
      " [  3  18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       252\n",
      "           1       1.00      0.86      0.92        21\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.99      0.93      0.96       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[245   1]\n",
      " [  5  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       246\n",
      "           1       0.96      0.81      0.88        27\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.97      0.91      0.93       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[262   0]\n",
      " [  3   8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       262\n",
      "           1       1.00      0.73      0.84        11\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.99      0.86      0.92       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[246   0]\n",
      " [  5  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       246\n",
      "           1       1.00      0.81      0.90        27\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.99      0.91      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[246   1]\n",
      " [  4  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       247\n",
      "           1       0.96      0.85      0.90        26\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.97      0.92      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[251   0]\n",
      " [  3  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       251\n",
      "           1       1.00      0.86      0.93        22\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.99      0.93      0.96       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[251   2]\n",
      " [  2  18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       253\n",
      "           1       0.90      0.90      0.90        20\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.95      0.95      0.95       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[248   2]\n",
      " [  6  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       250\n",
      "           1       0.89      0.74      0.81        23\n",
      "\n",
      "    accuracy                           0.97       273\n",
      "   macro avg       0.94      0.87      0.90       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[247   0]\n",
      " [  5  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       247\n",
      "           1       1.00      0.81      0.89        26\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.99      0.90      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[240   1]\n",
      " [  6  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       241\n",
      "           1       0.96      0.81      0.88        32\n",
      "\n",
      "    accuracy                           0.97       273\n",
      "   macro avg       0.97      0.90      0.93       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[242   0]\n",
      " [  4  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       242\n",
      "           1       1.00      0.87      0.93        31\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.99      0.94      0.96       273\n",
      "weighted avg       0.99      0.99      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[253   0]\n",
      " [  5  15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       253\n",
      "           1       1.00      0.75      0.86        20\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.99      0.88      0.92       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[247   1]\n",
      " [  4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       248\n",
      "           1       0.95      0.84      0.89        25\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.97      0.92      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[246   2]\n",
      " [  3  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       248\n",
      "           1       0.92      0.88      0.90        25\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.95      0.94      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[241   1]\n",
      " [  8  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       242\n",
      "           1       0.96      0.74      0.84        31\n",
      "\n",
      "    accuracy                           0.97       273\n",
      "   macro avg       0.96      0.87      0.91       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[248   1]\n",
      " [  2  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       249\n",
      "           1       0.96      0.92      0.94        24\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.97      0.96      0.97       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[243   2]\n",
      " [  4  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       245\n",
      "           1       0.92      0.86      0.89        28\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.95      0.92      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[249   1]\n",
      " [  7  16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       250\n",
      "           1       0.94      0.70      0.80        23\n",
      "\n",
      "    accuracy                           0.97       273\n",
      "   macro avg       0.96      0.85      0.89       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[246   0]\n",
      " [  3  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       246\n",
      "           1       1.00      0.89      0.94        27\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.99      0.94      0.97       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[249   1]\n",
      " [  5  18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       250\n",
      "           1       0.95      0.78      0.86        23\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.96      0.89      0.92       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[251   1]\n",
      " [  3  18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       252\n",
      "           1       0.95      0.86      0.90        21\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.97      0.93      0.95       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[240   2]\n",
      " [  4  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       242\n",
      "           1       0.93      0.87      0.90        31\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.96      0.93      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[253   1]\n",
      " [  4  15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       254\n",
      "           1       0.94      0.79      0.86        19\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.96      0.89      0.92       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[258   0]\n",
      " [  4  11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       258\n",
      "           1       1.00      0.73      0.85        15\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.99      0.87      0.92       273\n",
      "weighted avg       0.99      0.99      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[248   1]\n",
      " [  3  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       249\n",
      "           1       0.95      0.88      0.91        24\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.97      0.94      0.95       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[245   0]\n",
      " [  4  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       245\n",
      "           1       1.00      0.86      0.92        28\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.99      0.93      0.96       273\n",
      "weighted avg       0.99      0.99      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[244   0]\n",
      " [  4  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       244\n",
      "           1       1.00      0.86      0.93        29\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.99      0.93      0.96       273\n",
      "weighted avg       0.99      0.99      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[243   1]\n",
      " [  3  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       244\n",
      "           1       0.96      0.90      0.93        29\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.98      0.95      0.96       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[243   1]\n",
      " [  4  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       244\n",
      "           1       0.96      0.86      0.91        29\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.97      0.93      0.95       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[247   2]\n",
      " [  3  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       249\n",
      "           1       0.91      0.88      0.89        24\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.95      0.93      0.94       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[249   2]\n",
      " [  5  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       251\n",
      "           1       0.89      0.77      0.83        22\n",
      "\n",
      "    accuracy                           0.97       273\n",
      "   macro avg       0.94      0.88      0.91       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[251   1]\n",
      " [  4  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       252\n",
      "           1       0.94      0.81      0.87        21\n",
      "\n",
      "    accuracy                           0.98       273\n",
      "   macro avg       0.96      0.90      0.93       273\n",
      "weighted avg       0.98      0.98      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[252   1]\n",
      " [  3  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       253\n",
      "           1       0.94      0.85      0.89        20\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.97      0.92      0.94       273\n",
      "weighted avg       0.99      0.99      0.98       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[247   1]\n",
      " [  3  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       248\n",
      "           1       0.96      0.88      0.92        25\n",
      "\n",
      "    accuracy                           0.99       273\n",
      "   macro avg       0.97      0.94      0.95       273\n",
      "weighted avg       0.99      0.99      0.99       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[242   1]\n",
      " [  6  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       243\n",
      "           1       0.96      0.80      0.87        30\n",
      "\n",
      "    accuracy                           0.97       273\n",
      "   macro avg       0.97      0.90      0.93       273\n",
      "weighted avg       0.97      0.97      0.97       273\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Das beste Modell über neue Random-States predicten lassen\n",
    "\n",
    "for i in np.arange(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = np.random.randint(100000))\n",
    "\n",
    "    y_pred = np.floor(df_results_sorted.iloc[0].model.predict(X_test))\n",
    "    report = sklearn.metrics.classification_report(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(confusion_matrix)\n",
    "    print(report)\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.804791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.056015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.643100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.769900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.802200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.845900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.921500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               f1\n",
       "count  100.000000\n",
       "mean     0.804791\n",
       "std      0.056015\n",
       "min      0.643100\n",
       "25%      0.769900\n",
       "50%      0.802200\n",
       "75%      0.845900\n",
       "max      0.921500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
