{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "whole-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0,/job:localhost/replica:0/task:0/device:CPU:0\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0', '/job:localhost/replica:0/task:0/device:GPU:0')\n",
      "GPUs für die Berechnung: 0\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Ein Zufalls-Seed für Reproduzierbarkeit\n",
    "np.random.seed(42)\n",
    "\n",
    "from datetime import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks, utils\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/cpu:0\", \"/gpu:0\"])\n",
    "print(f\"GPUs für die Berechnung: {len(tf.config.experimental.list_physical_devices('GPU'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lightweight-breathing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3101</th>\n",
       "      <th>3102</th>\n",
       "      <th>3103</th>\n",
       "      <th>3104</th>\n",
       "      <th>3105</th>\n",
       "      <th>3106</th>\n",
       "      <th>3107</th>\n",
       "      <th>3108</th>\n",
       "      <th>3109</th>\n",
       "      <th>3110</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD335</th>\n",
       "      <td>34292.0</td>\n",
       "      <td>20670.0</td>\n",
       "      <td>18413.0</td>\n",
       "      <td>9981.0</td>\n",
       "      <td>7071.0</td>\n",
       "      <td>6881.0</td>\n",
       "      <td>5411.0</td>\n",
       "      <td>5335.0</td>\n",
       "      <td>5289.0</td>\n",
       "      <td>4741.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD643</th>\n",
       "      <td>15243.0</td>\n",
       "      <td>64328.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4507.0</td>\n",
       "      <td>3216.0</td>\n",
       "      <td>15630.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD539</th>\n",
       "      <td>22182.0</td>\n",
       "      <td>21589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11501.0</td>\n",
       "      <td>33619.0</td>\n",
       "      <td>3638.0</td>\n",
       "      <td>5053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD078</th>\n",
       "      <td>0.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>2305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19734.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD421</th>\n",
       "      <td>5154.0</td>\n",
       "      <td>12101.0</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>6316.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD202</th>\n",
       "      <td>14565.0</td>\n",
       "      <td>24920.0</td>\n",
       "      <td>3543.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37768.0</td>\n",
       "      <td>48660.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD544</th>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18543.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD422</th>\n",
       "      <td>5718.0</td>\n",
       "      <td>18420.0</td>\n",
       "      <td>9534.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4791.0</td>\n",
       "      <td>2770.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629.SubjectIBD522</th>\n",
       "      <td>3151.0</td>\n",
       "      <td>7071.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>4472.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681 rows × 3111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0        1        2       3       4        5     \\\n",
       "1629.SubjectIBD335  34292.0  20670.0  18413.0  9981.0  7071.0   6881.0   \n",
       "1629.SubjectIBD643  15243.0  64328.0      0.0     0.0     0.0      4.0   \n",
       "1629.SubjectIBD539  22182.0  21589.0      0.0  1365.0     0.0  11501.0   \n",
       "1629.SubjectIBD078      0.0    805.0      0.0     0.0     0.0      4.0   \n",
       "1629.SubjectIBD671      0.0  19734.0      0.0     0.0     0.0      0.0   \n",
       "...                     ...      ...      ...     ...     ...      ...   \n",
       "1629.SubjectIBD421   5154.0  12101.0   1572.0    62.0   190.0   1448.0   \n",
       "1629.SubjectIBD202  14565.0  24920.0   3543.0     0.0     0.0      0.0   \n",
       "1629.SubjectIBD544     32.0     52.0     31.0     0.0     0.0      2.0   \n",
       "1629.SubjectIBD422   5718.0  18420.0   9534.0     0.0     0.0      0.0   \n",
       "1629.SubjectIBD522   3151.0   7071.0    677.0    73.0   110.0    102.0   \n",
       "\n",
       "                       6       7        8        9     ... 3101 3102 3103  \\\n",
       "1629.SubjectIBD335   5411.0  5335.0   5289.0   4741.0  ...  0.0  0.0  0.0   \n",
       "1629.SubjectIBD643   4507.0  3216.0  15630.0    199.0  ...  0.0  0.0  0.0   \n",
       "1629.SubjectIBD539  33619.0  3638.0   5053.0      0.0  ...  0.0  0.0  0.0   \n",
       "1629.SubjectIBD078    330.0  2305.0      0.0      8.0  ...  0.0  0.0  0.0   \n",
       "1629.SubjectIBD671    215.0     0.0      0.0    699.0  ...  0.0  0.0  0.0   \n",
       "...                     ...     ...      ...      ...  ...  ...  ...  ...   \n",
       "1629.SubjectIBD421   6316.0  2205.0   1885.0      0.0  ...  0.0  0.0  0.0   \n",
       "1629.SubjectIBD202     63.0     0.0  37768.0  48660.0  ...  0.0  0.0  0.0   \n",
       "1629.SubjectIBD544  18543.0     0.0      3.0     45.0  ...  0.0  0.0  0.0   \n",
       "1629.SubjectIBD422   4791.0  2770.0      0.0    588.0  ...  0.0  0.0  0.0   \n",
       "1629.SubjectIBD522   4472.0   377.0      0.0     23.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "                   3104 3105 3106 3107 3108   3109  3110  \n",
       "1629.SubjectIBD335  0.0  0.0  0.0  0.0  0.0    0.0   0.0  \n",
       "1629.SubjectIBD643  0.0  0.0  0.0  0.0  0.0    0.0   0.0  \n",
       "1629.SubjectIBD539  0.0  0.0  0.0  0.0  0.0    0.0   0.0  \n",
       "1629.SubjectIBD078  0.0  0.0  0.0  0.0  0.0    0.0   0.0  \n",
       "1629.SubjectIBD671  0.0  0.0  0.0  0.0  0.0    0.0   0.0  \n",
       "...                 ...  ...  ...  ...  ...    ...   ...  \n",
       "1629.SubjectIBD421  0.0  0.0  0.0  0.0  0.0    0.0   0.0  \n",
       "1629.SubjectIBD202  0.0  0.0  0.0  0.0  0.0    0.0   0.0  \n",
       "1629.SubjectIBD544  0.0  0.0  0.0  0.0  0.0  946.0  31.0  \n",
       "1629.SubjectIBD422  0.0  0.0  0.0  0.0  0.0    0.0   0.0  \n",
       "1629.SubjectIBD522  0.0  0.0  0.0  0.0  0.0    0.0   0.0  \n",
       "\n",
       "[681 rows x 3111 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Metadaten einlesen\n",
    "df = pd.read_csv(\"NIHMS841832-supplement-1.csv\", sep=',')\n",
    "    \n",
    "#Ergebnisse des Feature Tables einlesen\n",
    "feature = pd.read_csv('feature_table.txt', sep='\\t').T\n",
    "feature = feature[1:][:-1]\n",
    "\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "appointed-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gesunde Kontrollgruppe\n",
    "HC = df[df.ibd_subtype.eq(\"HC\")]\n",
    "\n",
    "#CCD\n",
    "CCD = df[df.ibd_subtype.eq(\"CCD\")]\n",
    "    \n",
    "#ICD-r\n",
    "ICD_r = df[df.ibd_subtype.eq(\"ICD_r\")]\n",
    "\n",
    "#ICD-nr\n",
    "ICD_nr = df[df.ibd_subtype.eq(\"ICD_nr\")]\n",
    "    \n",
    "#UCD\n",
    "UC = df[df.ibd_subtype.eq(\"UC\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "french-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitt nach Patient. Alle Zeitpunkte eines Patienten entweder in Train oder Test.\n",
    "def split_function(tSize, random_state, table, metadata, hc_group):\n",
    "    patientSamples = {}\n",
    "    liste = []\n",
    "\n",
    "    for row in metadata.index:\n",
    "        liste.append(metadata['patientnumber'][row])\n",
    "\n",
    "    menge = set(liste)  \n",
    "\n",
    "    for e in menge:\n",
    "        newPatient = metadata[metadata.patientnumber.eq(e)]\n",
    "        patientSamples[e] = list(newPatient['sample_name'])\n",
    "\n",
    "    shuffleListe = list(menge)\n",
    "    random.Random(random_state).shuffle(shuffleListe)\n",
    "\n",
    "    #Split\n",
    "    trainSize = int(np.round(tSize * len(shuffleListe), 0))\n",
    "    testSize = len(shuffleListe) - trainSize\n",
    "\n",
    "    X_trainEntry = shuffleListe[0:trainSize]\n",
    "    X_testEntry = shuffleListe[trainSize:len(shuffleListe)]\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in X_trainEntry:\n",
    "        try:\n",
    "            value = patientSamples[i]\n",
    "            for sample_name in value:\n",
    "                for row in table.index:\n",
    "                    if(row == sample_name):\n",
    "                        temp = table.loc[[row]].values[0]\n",
    "                        X_train.append(temp)\n",
    "                        if any(True for val in hc_group['sample_name'] if val == row):\n",
    "                            y_train.append(1)\n",
    "                        else:\n",
    "                            y_train.append(0)\n",
    "        except KeyError as e:\n",
    "            fehler += 1\n",
    "            print('I got a KeyError - reason \"%s\"' % str(e))\n",
    "\n",
    "\n",
    "    X_test = []   \n",
    "    y_test = []\n",
    "    for i in X_testEntry:\n",
    "        try:\n",
    "            value = patientSamples[i]\n",
    "            for sample_name in value:\n",
    "                for row in table.index:\n",
    "                    if(row == sample_name):\n",
    "                        temp = table.loc[[row]].values[0]\n",
    "                        X_test.append(temp)\n",
    "                        if any(True for val in hc_group['sample_name'] if val == row):\n",
    "                            y_test.append(1)\n",
    "                        else:\n",
    "                            y_test.append(0)\n",
    "        except KeyError as e:\n",
    "            fehler += 1\n",
    "            print('I got a KeyError - reason \"%s\"' % str(e))\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "piano-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn(i):\n",
    "    #Split Test und Trainingsdaten für jede Gruppe\n",
    "    X_trainHC, X_testHC, y_trainHC, y_testHC = split_function(tSize=0.5, random_state=i, table=feature, metadata=HC, hc_group=HC)\n",
    "    X_trainCCD, X_testCCD, y_trainCCD, y_testCCD = split_function(tSize=0.75, random_state=i, table=feature, metadata=CCD, hc_group=HC)\n",
    "    X_trainICD_r, X_testICD_r, y_trainICD_r, y_testICD_r = split_function(tSize=0.75, random_state=i, table=feature, metadata=ICD_r, hc_group=HC)\n",
    "    X_trainICD_nr, X_testICD_nr, y_trainICD_nr, y_testICD_nr = split_function(tSize=0.75, random_state=i, table=feature, metadata=ICD_nr, hc_group=HC)\n",
    "    X_trainUC, X_testUC, y_trainUC, y_testUC = split_function(tSize=0.75, random_state=i, table=feature, metadata=UC, hc_group=HC)\n",
    "\n",
    "    X_train = np.concatenate((X_trainHC,  X_trainCCD,  X_trainICD_r,  X_trainICD_nr, X_trainUC), axis=0)\n",
    "    X_test = np.concatenate((X_testHC,  X_testCCD,  X_testICD_r,  X_testICD_nr, X_testUC), axis=0)\n",
    "    y_train = np.concatenate((y_trainHC,  y_trainCCD,  y_trainICD_r,  y_trainICD_nr, y_trainUC), axis=0)\n",
    "    y_test = np.concatenate((y_testHC,  y_testCCD,  y_testICD_r,  y_testICD_nr, y_testUC), axis=0)\n",
    "\n",
    "\n",
    "    trainSize = len(X_train)/(len(X_train)+len(X_test))\n",
    "    testSize =len(X_test)/(len(X_train)+len(X_test)) \n",
    "\n",
    "    HCTrainSize = len(X_trainHC)/(len(X_trainHC)+len(X_testHC))\n",
    "    HCTestSize = len(X_testHC)/(len(X_trainHC)+len(X_testHC))                          \n",
    "\n",
    "    CCDTrainSize = len(X_trainCCD)/(len(X_trainCCD)+len(X_testCCD))\n",
    "    CCDTestSize = len(X_testCCD)/(len(X_trainCCD)+len(X_testCCD))   \n",
    "\n",
    "    ICD_rTrainSize = len(X_trainICD_r)/(len(X_trainICD_r)+len(X_testICD_r))\n",
    "    ICD_rTestSize = len(X_testICD_r)/(len(X_trainICD_r)+len(X_testICD_r)) \n",
    "\n",
    "    ICD_nrTrainSize = len(X_trainICD_nr)/(len(X_trainICD_nr)+len(X_testICD_nr))\n",
    "    ICD_nrTestSize = len(X_testICD_nr)/(len(X_trainICD_nr)+len(X_testICD_nr)) \n",
    "\n",
    "    UCTrainSize = len(X_trainUC)/(len(X_trainUC)+len(X_testUC))\n",
    "    UCTestSize = len(X_testUC)/(len(X_trainUC)+len(X_testUC))  \n",
    "\n",
    "\n",
    "    #Feature Scaling\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Das Modell soll aufhören zu rechnen, falls es keine nennenswerten Verbesserungen mehr gibt\n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        min_delta=0.001,\n",
    "        patience=64,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "\n",
    "    #class_weights = dict(enumerate(class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)))\n",
    "\n",
    "    # Das NN besteht aus einer Mischung von Dense-, Normalization- und Dropout-Layern.\n",
    "    # Dropout führt allem Anschein nach zu schlechterem F1\n",
    "    # Weniger LUs führen zu besseren Ergebnissen\n",
    "    with mirrored_strategy.scope():\n",
    "        network = keras.Sequential([\n",
    "            #layers.BatchNormalization(),\n",
    "            layers.Dense(24, activation='sigmoid', input_shape=[X_train.shape[1]]),\n",
    "            layers.Dense(24, activation='sigmoid'),\n",
    "            layers.Dense(24, activation='sigmoid'),\n",
    "            layers.Dense(24, activation='sigmoid'),\n",
    "            layers.Dense(1, activation='sigmoid'),\n",
    "        ])\n",
    "\n",
    "        # NN kompilieren\n",
    "        network.compile(\n",
    "            optimizer='adamax',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[keras.metrics.BinaryAccuracy()]\n",
    "        )\n",
    "\n",
    "        # NN trainieren\n",
    "        history = network.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            batch_size=179,\n",
    "            #class_weight=class_weights,\n",
    "            epochs=512,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "    # Scores berechnen\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "\n",
    "    y_pred = network.predict(X_test)\n",
    "    #print(y_pred)\n",
    "    y_pred_corrected = []\n",
    "\n",
    "    for pred in y_pred:\n",
    "        if pred >= 0.5:\n",
    "            y_pred_corrected.append(1)\n",
    "        else: \n",
    "            y_pred_corrected.append(0)\n",
    "            \n",
    "    f1 = f1_score(y_test, y_pred_corrected, average='macro')\n",
    "\n",
    "    print(str(0) + \": \" + \"f1_score: \" + str(f1) + \"    \" + str(np.round(trainSize, 2)) +\"/\"+ str(np.round(testSize, 2)) + \" Gesamt-Split\")\n",
    "    print(str(np.round(HCTrainSize, 2)) +\"/\"+ str(np.round(HCTestSize, 2)) + \" HC-Split\")\n",
    "    print(str(np.round(CCDTrainSize, 2)) +\"/\"+ str(np.round(CCDTestSize, 2)) + \" CCD-Split\")\n",
    "    print(str(np.round(ICD_rTrainSize, 2)) +\"/\"+ str(np.round(ICD_rTestSize, 2)) + \" ICD_r-Split\")\n",
    "    print(str(np.round(ICD_nrTrainSize, 2)) +\"/\"+ str(np.round(ICD_nrTestSize, 2)) + \" ICD_nr-Split\")\n",
    "    print(str(np.round(UCTrainSize, 2)) +\"/\"+ str(np.round(UCTestSize, 2)) + \" UC-Split\")\n",
    "\n",
    "    report = sklearn.metrics.classification_report(y_test, y_pred_corrected)\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_test, y_pred_corrected)\n",
    "    print(confusion_matrix)\n",
    "    print(report)\n",
    "    history_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n",
    "    history_df.loc[5:, ['loss', 'val_loss']].plot()\n",
    "\n",
    "    return f1, report, network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "variable-morris",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c71d6bfc4fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-0e9650acb19e>\u001b[0m in \u001b[0;36mnn\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         )\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1381\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     worker_iterators = _create_iterators_per_worker(self._cloned_datasets,\n\u001b[1;32m   1113\u001b[0m                                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m                                                     enable_legacy_iterators)\n\u001b[0m\u001b[1;32m   1115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menable_legacy_iterators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m       iterator = DistributedIteratorV1(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m_create_iterators_per_worker\u001b[0;34m(worker_datasets, input_workers, enable_legacy_iterators, options)\u001b[0m\n\u001b[1;32m   1918\u001b[0m             \u001b[0mworker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m             \u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworker_devices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1920\u001b[0;31m             options=options)\n\u001b[0m\u001b[1;32m   1921\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m         iterator = _SingleWorkerDatasetIterator(worker_datasets[i], worker,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, worker, devices, components, element_spec, options)\u001b[0m\n\u001b[1;32m   1767\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m       super(_SingleWorkerOwnedDatasetIterator,\n\u001b[0;32m-> 1769\u001b[0;31m             self).__init__(dataset, worker, devices, options)\n\u001b[0m\u001b[1;32m   1770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, worker, devices, options)\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1572\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m_make_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1778\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m         self._iterator = multi_device_iterator_ops.OwnedMultiDeviceIterator(\n\u001b[0;32m-> 1780\u001b[0;31m             self._dataset, self._devices, source_device=host_device)\n\u001b[0m\u001b[1;32m   1781\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, devices, max_buffer_size, prefetch_buffer_size, source_device, components, element_spec)\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_device_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             max_buffer_size=max_buffer_size)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m       \u001b[0mprototype_device_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmulti_device_iterator_init\u001b[0;34m(dataset, multi_device_iterator, max_buffer_size, name)\u001b[0m\n\u001b[1;32m   3659\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   3660\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultiDeviceIteratorInit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_device_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3661\u001b[0;31m         max_buffer_size)\n\u001b[0m\u001b[1;32m   3662\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3663\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 100 verschiedene Modelle trainieren und in einen DataFrame speichern\n",
    "# Das kann ein paar Stunden dauern\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i in np.arange(20):\n",
    "    f1, report, model = nn(i)\n",
    "    results[i] = [model, f1, report]\n",
    "    clear_output()\n",
    "    df_results = pd.DataFrame.from_dict(results, orient='index', columns=['model', 'f1', 'report'])\n",
    "    display(df_results)\n",
    "\n",
    "\n",
    "#df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame nach bestem F1-Score sortieren\n",
    "df_results_sorted = df_results.sort_values(by=['f1'], ascending=False)\n",
    "\n",
    "# Die besten 10 Modelle speichern\n",
    "#for i in np.arange(10):\n",
    "#    df_results_sorted.iloc[i].model.save(f'models/best_otu/model{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
